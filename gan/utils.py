# Project: EEG-GAN
# Author: Samuel Boehm
# E-Mail: <samuel-boehm@web.de>

import torch

from gan.model.gan import GAN
import os 
import torch
from gan.paths import results_path, data_path
from gan.data.dataset import EEGGAN_Dataset



def to_device(device:torch.device, *elements):
    return [element.to(device) for element in elements]


def generate_data(model_token, stage, n_samples):
    """
    Generate fake data with a trained model. 
  
    Arguments:
    ----------
        model_token: str 
            The token of the model generated by W&B.
        stage: int
            The stage of the model.
        n_samples: int
            The number of samples to generate.
    
    Returns:
    ----------
        ds: EEGGAN_Dataset
            The generated data.
    """
    model_token = os.path.join(results_path, 'EEGGAN', model_token, "checkpoints/last.ckpt")
    print(model_token)
    model = GAN.load_from_checkpoint(
                checkpoint_path=model_token,
                map_location=torch.device('cpu'),
                )
    model.eval()
    model.freeze()

    # Set Stage:
    model.generator.set_stage(stage)
    model.critic.set_stage(stage)

    model.generator.fading = False
    model.critic.fading = False

    fs_stage = int((model.hparams.fs/2**(model.hparams.n_stages - (stage))))

        
    print('model fs', fs_stage)
    print(f'model current stage: {model.generator.cur_stage}/{model.hparams.n_stages}')

    # We need to generate the data in batches, because the GPU memory is not
    # big enough to generate all data at once.
    batch_size = 128

    for batch in range(n_samples // batch_size):
        z = torch.randn(batch_size, model.hparams.latent_dim)
        y_fake_batch = torch.randint(low=0, high=model.hparams.n_classes,
                                size=(batch_size,), dtype=torch.int32)

        # generate fake batch:
        X_fake_batch = model.forward(z, y_fake_batch)

        if batch == 0:
            X_fake = X_fake_batch
            y_fake = y_fake_batch
        else:
            X_fake = torch.cat((X_fake, X_fake_batch), dim=0)
            y_fake = torch.cat((y_fake, y_fake_batch), dim=0)

    if n_samples % batch_size != 0:
        z = torch.randn(n_samples % batch_size, model.hparams.latent_dim)
        y_fake_batch = torch.randint(low=0, high=model.hparams.n_classes,
                                size=(n_samples % batch_size,), dtype=torch.int32)

        # generate fake batch:
        X_fake_batch = model.forward(z, y_fake_batch)

        if batch_size >= n_samples:
            X_fake = X_fake_batch
            y_fake = y_fake_batch
        else:
            X_fake = torch.cat((X_fake, X_fake_batch), dim=0)
            y_fake = torch.cat((y_fake, y_fake_batch), dim=0)


    X_fake = X_fake.detach().numpy()
    y_fake = y_fake.detach().numpy()

    ds = EEGGAN_Dataset(['session',], fs_stage)

    ds.add_data(X_fake, y_fake, [1,])

    return ds